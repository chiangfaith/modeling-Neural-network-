{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size 一次载入多少样本\n",
    "num_works 多进程，windows大于零，下经常出错\n",
    "drop_last 如果多余样本是否舍去"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = torchvision.datasets.CIFAR10(\"./dataset\", train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=4, shuffle= True, num_workers=0, drop_last= False)\n",
    "\n",
    "img,target = test_data[0]\n",
    "print(img.shape)\n",
    "print(target)\n",
    "\n",
    "writer = SummaryWriter(\"dataLoader\")\n",
    "step = 0\n",
    "for data in test_loader:\n",
    "        imgs,targets = data\n",
    "        print(img.shape)\n",
    "        print(target)\n",
    "        writer.add_images(\"test_data_drop_last\",imgs,step)\n",
    "        step = step + 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset\n",
    "    getitem():\n",
    "        return img,target\n",
    "\n",
    "    dataloader(batch_size = 4)\n",
    "        return imgs,targets\n",
    "\n",
    "    img0,target0 = dataset[0]\n",
    "    img1,targrt1 = dataset[1]\n",
    "    img2,targrt2 = dataset[2]\n",
    "    imgs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,input):\n",
    "        output = input + 1\n",
    "        return output\n",
    "    \n",
    "tudui = Tudui()\n",
    "x= torch.tensor(1.0)\n",
    "output = tudui(1)  \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.nn import Conv2d\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(\"../data\",train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                       download=False)\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.conv1 = Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding =0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "tudui = Tudui()\n",
    "\n",
    "writer = SummaryWriter(\"../logs\")\n",
    "step = 0\n",
    "\n",
    "for data in dataloader:\n",
    "    imgs,target = data\n",
    "    output = tudui(imgs)\n",
    "    print(imgs.shape)\n",
    "    print(output.shape)\n",
    "    writer.add_images('input',imgs,step)\n",
    "    \n",
    "    torch.reshape(output,(-1,3,30,30))\n",
    "    writer.add_images('output',output,step)\n",
    "    \n",
    "    step = step + 1 \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大池化的使用\n",
    "maxpool 下采样\n",
    "maxuponpool 上采样\n",
    "kernel_size 取最大值的窗口\n",
    "stride 步长，默认为1\n",
    "dilation 空洞卷积\n",
    "ceil_mode(ceil or floor)向上或者向下取整，当stride过大时，True第二步就会保留不足的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import MaxPool2d\n",
    "import torchvision\n",
    "\n",
    "#取出数据\n",
    "dataset = torchvision.datasets.CIFAR10(\"../data\", train=False, download=True, \n",
    "                                       transform= torchvision.transforms.ToTensor())\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "# input = torch.tensor(\n",
    "#     [[3,1,3,2,5],\n",
    "#     [7,3,5,6,2],\n",
    "#     [1,3,4,7,9],\n",
    "#     [4,6,2,1,4],\n",
    "#     [1,4,6,3,1]], dtype= torch.float32\n",
    "# )\n",
    "# input = torch.reshape(input,(-1,1,5,5))\n",
    "# print(input.shape)\n",
    "\n",
    "#卷积神经网络基本架构\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=3, ceil_mode=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.maxpool1(input)\n",
    "        return output\n",
    "    print(output)\n",
    "    \n",
    "tudui = Tudui()\n",
    "\n",
    "writer = SummaryWriter ('../logs_maxpool')\n",
    "step = 0\n",
    "\n",
    "#分批次训练\n",
    "for data in dataloader:\n",
    "    imgs, target = data\n",
    "    writer.add_images(\"input\", imgs, step)\n",
    "    output = tudui(imgs)\n",
    "    writer.add_images(\"output\", output, step)\n",
    "    step = step + 1\n",
    "\n",
    "output = tudui(input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding用零或其他常数进行填充\n",
    "非线性激活RELU，当大于0就取其值，小于0就取0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import Sigmoid\n",
    "\n",
    "input = torch.tensor([[1,2],\n",
    "                      [-1,3]])\n",
    "output = torch.reshape(input,(-1,1,2,2))\n",
    "print(output.shape)\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.relu1 = ReLU() #inplace为False时保留原始输入数据\n",
    "        self.sigmoid1 = Sigmoid()\n",
    "    \n",
    "    def forward(self,input):\n",
    "        output = self.sigmoid1(input)\n",
    "        return output\n",
    "    print(output)\n",
    "\n",
    "tudui = Tudui()\n",
    "output = tudui(input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TCN网络的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d,self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "    def forward(self, x):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        此处指的是剪裁模块，剪裁多出来的padding\n",
    "        \"\"\"\n",
    "        return x[:,:,:-self.chomp_size].contiguous()\n",
    "    \n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        \"\"\"[相当于一个Residual Block]\n",
    "\n",
    "        Args:\n",
    "            n_inputs ([int]): [输入通道数]\n",
    "            n_outputs ([int]): [输出通道数]\n",
    "            kernel_size ([int]): [卷积核]\n",
    "            stride ([int]): [步长，一般为1]\n",
    "            dilation ([int]): [膨胀系数]\n",
    "            padding ([int]): [填充系数]\n",
    "            dropout (float, optional): [丢弃比率]. Defaults to 0.2.\n",
    "        \"\"\"\n",
    "        \n",
    "        super(TemporalBlock, self),__init__()\n",
    "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding,\n",
    "                                           dilation=dilation))\n",
    "        #经过conv1,输出的size其实是(Batch_size, input_channel, seq_len+padding)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.conv2 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size, stride=stride, padding=padding,\n",
    "                                           dilation=dilation))\n",
    "        #经过conv1,输出的size其实是(Batch_size, input_channel, seq_len+padding)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1, \n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        \n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs !=n_outputs else None\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        \"\"\"[参数初始化]\n",
    "        \n",
    "        \"\"\"\n",
    "        self.conv1.weight.data.normal_(0,0.01)\n",
    "        self.conv2.weight.data.normal_(0,0.01)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0,0.01)\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"[参数]\n",
    "\n",
    "        Args:\n",
    "            para x ([int]): [size of Batch, input_channel, seq_len]\n",
    "        \"\"\"\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "    \n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout = 0.2):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            num_inputs ([int]): [输入通道数]\n",
    "            num_channels ([list]): [每层的hidden_channel数，例如[25,25,25,25]表示有4个隐层，每个层有25个神经单元]\n",
    "            hernel_size (int, optional): [description]. Defaults to 2.\n",
    "            dropout (float, optional): [description]. Defaults to 0.2.\n",
    "        \"\"\"\n",
    "        super().__init__(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2**i #膨胀系数：1，2，4，8...\n",
    "            in_channels = num_inputs if i ==0 else num_channels[i-1] #确定每层的输入通道数\n",
    "            out_channels = num_channels[i] #确定每层时输出通道数\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1)*dilation_size, dropout=dropout)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入x的结构不同于RNN，一般RNN的size为(Batch, seq_len, channels)或者(seq_len, Batch, channels)，\n",
    "        这里把seq_len放在channels后面，把所有时间步的数据拼起来，当做Conv1d的输入尺寸，实现卷积跨时间步的操作，\n",
    "        很巧妙的设计。\n",
    "        \n",
    "        :param x: size of (Batch, input_channel, seq_len)\n",
    "        :return: size of (Batch, output_channel, seq_len)\n",
    "        \"\"\"    \n",
    "        return self.network(x)\n",
    "tcn = TemporalConvNet(3,[10,10,10,10])\n",
    "print(tcn)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Linear\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"../data\",train = False,transform= torchvision.transforms.ToTensor(),\n",
    "                                       download = True)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64)\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.linear = Linear(196608, 10)\n",
    "    def forward(self, input):\n",
    "        output = self.linear(input)\n",
    "        return output\n",
    "\n",
    "tudui = Tudui()\n",
    "\n",
    "for data in dataloader:\n",
    "    imgs, target = data\n",
    "    print(imgs.shape)\n",
    "    # output = torch.reshape(imgs,(1,1,1,-1))\n",
    "    torch.flatten(imgs)\n",
    "    print(output.shape)\n",
    "    output = tudui(output)\n",
    "    print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "容器类Sequential \n",
    "\n",
    "对CIFAR10进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn import Sequential, Conv2d, Flatten, MaxPool2d, Linear\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.conv1 = Conv2d(3,32,5,padding=2)\n",
    "        self.maxpool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(32,32,5,padding=2)\n",
    "        self.maxpool2 = MaxPool2d(2)\n",
    "        self.conv3 = Conv2d(32,64,5,padding=2)\n",
    "        self.maxpool3 = MaxPool2d(2)\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(1024,64)\n",
    "        self.linear2 = Linear(64,10)\n",
    "        \n",
    "        # self.model = Sequential(\n",
    "        #     Conv2d(3,32,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Conv2d(32,32,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Conv2d(32,64,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Flatten(),\n",
    "        #     Linear(1024,64),\n",
    "        #     Linear(64,10) \n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "tudui = Tudui()\n",
    "print(tudui)\n",
    "\n",
    "input = torch.ones((64,3,32,32))\n",
    "output = tudui(input)\n",
    "print(output)\n",
    "\n",
    "writer = SummaryWriter(\"..\\logs_seq\")\n",
    "writer.add_graph(tudui, input)\n",
    "writer.close()\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数与反向传播\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details.\n",
      "<a href='https://aka.ms/kernelFailuresDllLoad'>了解更多</a>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import L1Loss, CrossEntropyLoss\n",
    "from torch import nn\n",
    "\n",
    "inputs= torch.tensor([1,2,3],dtype = torch.float32)\n",
    "targets = torch.tensor([1,2,5],dtype = torch.float32)\n",
    "\n",
    "inputs = torch.reshape(inputs,(1,1,1,3))\n",
    "targets = torch.reshape(targets,(1,1,1,3))\n",
    "\n",
    "loss = L1Loss(reduction=\"sum\")\n",
    "result = loss(inputs, targets)\n",
    "\n",
    "loss_mse = nn.MSELoss()\n",
    "result_mse = loss_mse(inputs,targets)\n",
    "\n",
    "print(result)\n",
    "print(result_mse)\n",
    "\n",
    "x = torch.tensor([0.1,0.2,0.3])\n",
    "y = torch.tensor([1])\n",
    "\n",
    "x = torch.reshape(x,(1,3))\n",
    "loss_cross = nn.CrossEntropyLoss()\n",
    "result_cross = loss_cross(x,y)\n",
    "print(result_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details.\n",
      "<a href='https://aka.ms/kernelFailuresDllLoad'>了解更多</a>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn import Sequential, Conv2d, Flatten, MaxPool2d, Linear\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"../data\",train=False,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.conv1 = Conv2d(3,32,5,padding=2)\n",
    "        self.maxpool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(32,32,5,padding=2)\n",
    "        self.maxpool2 = MaxPool2d(2)\n",
    "        self.conv3 = Conv2d(32,64,5,padding=2)\n",
    "        self.maxpool3 = MaxPool2d(2)\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(1024,64)\n",
    "        self.linear2 = Linear(64,10)\n",
    "        \n",
    "        # self.model = Sequential(\n",
    "        #     Conv2d(3,32,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Conv2d(32,32,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Conv2d(32,64,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Flatten(),\n",
    "        #     Linear(1024,64),\n",
    "        #     Linear(64,10) \n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "tudui = Tudui()\n",
    "print(tudui)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "tudui = Tudui()\n",
    "\n",
    "for data in dataloader:\n",
    "    imgs, targets = data\n",
    "    outputs = tudui(imgs)\n",
    "    print(outputs)\n",
    "    print(targets)\n",
    "    \n",
    "    result_loss = loss(outputs,targets)\n",
    "    print(result_loss)\n",
    "\n",
    "\n",
    "# writer = SummaryWriter(\"..\\logs_seq\")\n",
    "# writer.add_graph(tudui, input)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as a dll could not be loaded. \n",
      "View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details.\n",
      "<a href='https://aka.ms/kernelFailuresDllLoad'>了解更多</a>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.nn import Sequential, Conv2d, Flatten, MaxPool2d, Linear, \n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(\"../data\",train=False,transform=torchvision.transforms.ToTensor(),\n",
    "                                       download = False)\n",
    "\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "\n",
    "class Tudui(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Tudui,self).__init__()\n",
    "        self.conv1 = Conv2d(3,32,5,padding=2)\n",
    "        self.maxpool1 = MaxPool2d(2)\n",
    "        self.conv2 = Conv2d(32,32,5,padding=2)\n",
    "        self.maxpool2 = MaxPool2d(2)\n",
    "        self.conv3 = Conv2d(32,64,5,padding=2)\n",
    "        self.maxpool3 = MaxPool2d(2)\n",
    "        self.flatten = Flatten()\n",
    "        self.linear1 = Linear(1024,64)\n",
    "        self.linear2 = Linear(64,10)\n",
    "        \n",
    "        # self.model = Sequential(\n",
    "        #     Conv2d(3,32,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Conv2d(32,32,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Conv2d(32,64,5,padding=2),\n",
    "        #     MaxPool2d(2),\n",
    "        #     Flatten(),\n",
    "        #     Linear(1024,64),\n",
    "        #     Linear(64,10) \n",
    "        # )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "tudui = Tudui()\n",
    "print(tudui)\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "tudui = Tudui()\n",
    "#构造优化器\n",
    "optim = torch.optim.RAdam(tudui.parameters(), lr=0.01)\n",
    "for epoch in range(20):\n",
    "    running_loss = 0.0\n",
    "    for data in dataloader:\n",
    "        imgs, targets = data\n",
    "        outputs = tudui(imgs)\n",
    "        print(outputs)\n",
    "        print(targets)\n",
    "        \n",
    "        result_loss = loss(outputs,targets)\n",
    "        optim.zero_grad()\n",
    "        result_loss.backward()\n",
    "        optim.step()\n",
    "        running_loss = running_loss + result_loss\n",
    "        \n",
    "        print(result_loss)\n",
    "\n",
    "\n",
    "# writer = SummaryWriter(\"..\\logs_seq\")\n",
    "# writer.add_graph(tudui, input)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0ccc3789cb73ec2cf6efe118b2e4ea54ef9f7083f7b41837e39127e72e9049fa"
  },
  "kernelspec": {
   "display_name": "jfz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
